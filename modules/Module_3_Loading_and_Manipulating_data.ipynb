{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtEguwYoTJJg"
   },
   "source": [
    "# Module 3: Loading & Manipulating Data\n",
    "\n",
    "In this module you'll learn about:\n",
    "\n",
    "- Importing libraries\n",
    "- File paths\n",
    "- Opening text files from your computer\n",
    "- Loading CSV files and iterating over rows\n",
    "- Loading CSV into a Pandas DataFrame\n",
    "- Exploring a DataFrame (including some descriptive statistics)\n",
    "- Filters / subsets of DataFrames\n",
    "- Editing DataFrames\n",
    "- Saving DataFrames as CSV files\n",
    "\n",
    "\n",
    "## Libraries\n",
    "\n",
    "Ready for some great Python news? You don't have to code everything by yourself from scratch! Many other people have written Python code that you can import into your own code, which will save you time and do a lot of work behind-the-scenes. We call the code written and packaged up by other people a \"library\", \"package\", or \"module\", although here we will just refer to them as libraries. \n",
    "\n",
    "The `import` statement is used whenever you want to import an external Python library that was written by someone else. Let's give that a go with the `os` library, which stands for \"Operating System\", and allows us to interact with other files on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the os library\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have `os` imported, we can use it. To call any of the functions within a library, you just type the library name followed by a full stop and the function name. The `os` library has a function called `getcwd()` which returns the current working directory (cwd), which is the place your current script is running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cwd and print it\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should show you the *path* where you've saved your scripts. \n",
    "\n",
    "## Paths\n",
    "\n",
    "Just a few notes on paths, as this will be useful to know when we start reading files from your computer. A path is the formal definition of the location of a file or folder on your harddrive. It basically shows which harddrive the file/folder is stored, together with the folders (also called directories) you need to traverse to get to a file/folder. This combination of folders showing you how to get to a file is called a *path*.\n",
    "\n",
    "If you are using Windows, the above cell will output something like: \"C:\\Users\\your_username\\Documents\\Scripts\", where \"C:\\\" is the harddrive it's stored on, and \"Users\\your_username\\Documents\\Scripts\" is the location within that harddrive. Note that the path uses backward slashes (`\\`).\n",
    "\n",
    "If you are running MacOS or Linux, the above cell will output something like: \"/home/your_username/Scripts\". Note that the path uses forward slashes (`/`). \n",
    "\n",
    "This whole path from the root folder to the folder where the file is kept, is called an *absolute path*. It is always the same, no matter where your script is. The other way we can find a file is via a *relative path*. This is relative to where your script is, and so if you want to open a file that is in the same folder as your script, you don't need to type the whole path, but can just use \"test.txt\". As Python 'knows' where it is, it knows where to find the test.txt file. \n",
    "\n",
    "A relative path can also be in a subfolder of a current folder, in which case it looks something like \"data/test.txt\". A special syntax (`../`) is used for going up a folder, like using the back button in your file explorer: \"../test.txt\", this will fetch the text.txt file in the folder above your script.\n",
    "\n",
    "You don't need to remember all this right now, but it's useful to know of these concepts when working with your own data.\n",
    "\n",
    "\n",
    "## Opening text files\n",
    "\n",
    "Quite often, research data is in the form of a text file (or can easily be converted to a text file). A text file is not only files that have the extension \".txt\", but basically any file that can be opened with Notepad (or TextEdit on Mac). This includes CSV (Comma Separated Values) files, which we'll come back to in the next section. \n",
    "\n",
    "To open a file in Python, we use the `open()` function, which requires some specific syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the text.txt file from the data folder, save the file under variable name 'file'\n",
    "with open('../data/text.txt') as file:\n",
    "    \n",
    "    # read the text within the file, and save it in the variable 'text'\n",
    "    text = file.read()\n",
    "\n",
    "# print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see in the `open()` function above, we used `../` to go up a folder, the into the data folder, and then the text.txt file? This is a relative path!\n",
    "\n",
    "So above we opened a text file and saved all the text as a string, which we saved in the `text` variable. This can be useful, but quite often with research data, you will find one entry, or one thing, per line. So it would be more useful to have each line as an item in a list. To do this, we use the `readlines()` function, instead of `read()`, like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the text.txt file from the data folder, save the file under variable name 'file'\n",
    "with open('../data/text.txt') as file:\n",
    "    \n",
    "    # read the text within the file, and save it in the variable 'lines'\n",
    "    text = file.read()\n",
    "    \n",
    "    # take the string in `text`, and split the lines, converting it to a list where every line is 1 item\n",
    "    lines = text.splitlines()\n",
    "\n",
    "# print it!\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have each line as an item in a list, we can loop over it using a `for` loop, like we did in the previous module. Before you run the cell below, read the code, and try to predict what it will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    print(len(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did that match your expectation?\n",
    "\n",
    "## CSV files\n",
    "\n",
    "CSV (short for Comma Separated Values, .csv) is a specific format for text files. Like the name suggests, it uses Commas to Separate Values, and this way we can store spreadsheet like information. This format is quite simple, which means it can easily be read by Excel, but also Python. It is often used as a way to transfer information between software packages, and also for long term storage. \n",
    "\n",
    "A CSV file is just a text file, so when you would open one in Notepad, it would look something like this:\n",
    "\n",
    "    width,height,weight\n",
    "    2,3,5\n",
    "    5,9,8\n",
    "\n",
    "Here we see a spreadsheet with 3 columns (width, height, weight), and 2 rows containing values. Each column is separated by a comma. As a .csv file is really just a text file, we can open it the same way as we did the text file above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the test.csv file from the data folder, save the file under variable name 'file'\n",
    "with open('../data/test.csv') as file:\n",
    "    \n",
    "    # read the text within the file, and save it in the variable 'lines'\n",
    "    text = file.read()\n",
    "    \n",
    "    # take the string in `text`, and split the lines, converting it to a list where every line is 1 item\n",
    "    lines = text.splitlines()\n",
    "\n",
    "# print it!\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but isn't super handy, because we now need to convert each line from a string (e.g. `'2,3,5'`) to a list (e.g. `[2, 3, 5]`). Instead, we can load and use the `csv` library, which has functions built in for reading CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv library\n",
    "import csv\n",
    "\n",
    "# open the test.csv file \n",
    "with open('../data/test.csv') as file:\n",
    "    \n",
    "    # read the file with the csv.reader function, which returns a list of rows\n",
    "    rows = csv.reader(file)\n",
    "    \n",
    "    # for each row\n",
    "    for row in rows:\n",
    "        \n",
    "        # print the row\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say we want to calculate the width/height ration for all our rows, and save these in a new list. This can be done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up empty list to hold all the ratios\n",
    "ratios = []\n",
    "\n",
    "# open the test.csv file \n",
    "with open('../data/test.csv') as file:\n",
    "    \n",
    "    # read the file with the csv.reader function, which returns a list of rows\n",
    "    rows = csv.reader(file)\n",
    "    \n",
    "    # for each row (reuse the row variable from previous cell, it still contains all the data!)\n",
    "    for row in rows:\n",
    "\n",
    "        # we don't want to do anything in the first row, as this contains the headers. \n",
    "        # we skip it by checking if the first column of the row is not 'width' (\"!=\" means 'is not')\n",
    "        if row[0] != 'width':\n",
    "\n",
    "            # calculate the ratio (0 = width, 1 - height)\n",
    "            ratio = float(row[0]) / float(row[1])\n",
    "\n",
    "            # add ratio to the list\n",
    "            ratios.append(ratio)\n",
    "        \n",
    "# print ratios\n",
    "print(ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above works, but it's a lot of code for something relatively simple, and you have to do a lot of stuff manually (loading the file, looping through rows, skipping headers). If your data looks like a spreadsheet, it is generally a lot easier to import the data into a so-called DataFrame. \n",
    "\n",
    "## Pandas DataFrames\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure, it is a type of variable just like lists and strings. 2-dimensional might sound complex, but really it just means that it contains data in rows and columns, just like your average spreadsheet. DataFrames can also do just about anything you can do in Excel, plus some extra stuff! A lot of our archaeological data is in this format, so if you start coding your own projects, it is likely that DataFrames will make your life easier. \n",
    "\n",
    "DataFrames are not part of the default Python installation, so we need to import the library first, just like we did with `os` and `csv`. The library that contains DataFrames is called `pandas`. Let's import it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above `import` statement not only imports the Pandas library but also gives it an alias or nickname — `pd`. This alias will save us from having to type out the entire words pandas each time we need to use it. Many Python libraries have commonly used aliases like pd. \n",
    "\n",
    "### Read in CSV File\n",
    "\n",
    "To read in a CSV file, we will use the function `pd.read_csv()` and insert the name of our desired file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Pandas DataFrame object — often abbreviated as df, e.g., `test_df`. A DataFrame looks and acts a lot like a spreadsheet. But it has special powers and functions that we will discuss below.\n",
    "\n",
    "When reading in the CSV file, we also specified delimiter. The delimiter specifies the character that separates or \"delimits\" the columns in our dataset. For CSV files, the delimiter will most often be a comma. (CSV is short for Comma Separated Values.) Sometimes, however, the delimiter of a CSV file might be a tab (\\t) or, more rarely, another character. Always inspect your data before loading to see which delimiter is used!\n",
    "\n",
    "### Display a DataFrame\n",
    "\n",
    "To see what data is stored in a DataFrame, you can use the print() function, like with any other variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the tabular structure of the data very well, and this is much easier to read than when we loaded the CSV manually. \n",
    "\n",
    "An even better way to view DataFrames is by simply typing the variable name into a cell. Jupyter Notebook will recognise the variable as a DataFrame, and apply some styling to make the data even easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a small table this doesn't matter that much, so let's load a bigger spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load artefacts file\n",
    "artefacts = pd.read_csv('../data/artefacts.csv', delimiter=',')\n",
    "\n",
    "# show data\n",
    "artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recognise this data, it's also used in the BA1 Data Analysis course. We will repeat some of the analyses and visualisations from that course, to show you how easy and flexible it is to do it in Python instead of Excel!\n",
    "\n",
    "This spreadsheet contains data from a field survey in the Italian research area Agro Pontino, just south of Rome. Each row is an observation (record) and describes a single artefact as found during the field survey. Artefacts that were discovered during a visit were numbered sequentially. Normally several artefacts are found on a arable field and several adjacent fields might together form one archaeological site. An arable field is often revisited several times to collect more artefacts in order to get a better picture of the site in size, function and date.\n",
    "\n",
    "Most of the variables used are categorical data (measurement level) with coded (numerical) values. These categorical data are particularly suitable for data analysis.  \n",
    "\n",
    "There are a few important things to note about the DataFrame displayed above:\n",
    "\n",
    "- Index\n",
    "    - The bolded ascending numbers in the very left-hand column of the DataFrame is called the Pandas Index. You can select rows based on the Index.\n",
    "    - This is similar to the row numbers in Excel\n",
    "    - By default, the Index is a sequence of numbers starting with zero. However, you can change the Index to something else, such as one of the columns in your dataset.\n",
    "\n",
    "- Rows x Columns\n",
    "\n",
    "    - Pandas reports how many rows and columns are in this dataset at the bottom of the output (606 x 12 columns).\n",
    "    - This is very useful!\n",
    "\n",
    "- Truncation\n",
    "\n",
    "    - The DataFrame is truncated, signaled by the ellipses (...) in the middle of the rows.\n",
    "    - The DataFrame is truncated because the default display setting is to show 10 rows. Anything more than 10 rows will be truncated. To display all the rows, we can alter the setting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max rows to display to 1000, more than the total of rows in the dataframe\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# show data again\n",
    "artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sections of a DataFrame\n",
    "\n",
    "To look at the first *n* rows in a DataFrame, we can use a method called `.head()`. \n",
    "\n",
    "Note, *n* is used in math/programming to denote any arbitrary number. In the below cell, *n* = 20 for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top 20 rows\n",
    "artefacts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the last *n* rows in a DataFrame, we can use a method called `.tail()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show bottom 40 rows\n",
    "artefacts.tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're more interested in seeing some rows througout your data, you can get a random sample by using `.sample()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefacts.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell this is a random sample by looking at the index numbers on the left: they are not sequential or sorted anymore! Run the above cell again to see the rows change, everytime you run `.sample()` you get a different, random sample.\n",
    "\n",
    "### Get Info and Statistics\n",
    "\n",
    "To get useful info about all the columns in the DataFrame, we can use `.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefacts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will tell us how many non-null, or non-blank, values are in each column, as well as what type of data is in each column. Unfortunately, Pandas have slightly different name for variable types, but here's a translation table:\n",
    "\n",
    "| Pandas Data Type | Explanation |\n",
    "|:----------------:|:-----------:|\n",
    "|      object      |    string   |\n",
    "|      float64     |    float    |\n",
    "|       int64      |   integer   |\n",
    "|    datetime64    |  date time  |\n",
    "\n",
    "To calculate descriptive (summary) statistics for every column in our DataFrame, we can use the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefacts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's certainly a lot easier and quicker than calculating all these values by using Excel formulas! However, these columns mainly contain nominal and ordinal data (categories and counting numbers). \n",
    "\n",
    "#### Exercise time!\n",
    "\n",
    "In the cells below, do the following:\n",
    "\n",
    "- Load the 'spearheads.csv' file from the data folder into a DataFrame, name the variable `spearheads`\n",
    "- Show and inspect the resulting DataFrame\n",
    "- Question: how many rows are in the DataFrame? (Take into account the index starts at 0!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 of the exercise:\n",
    "\n",
    "- Calculate and show the descriptive statistics for `spearheads`\n",
    "- Question: does the 'count' match your answer above?\n",
    "- Question: what is the maximum value for 'weight'?\n",
    "- Question: what is the average date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns\n",
    "\n",
    "To select a column from the DataFrame, we will type the name of the DataFrame followed by square brackets and a column name in quotations marks, just like we do when selecting an element from a list or dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and show column 'con'\n",
    "spearheads['con']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, a single column in a DataFrame is a Series object. We can ask Python to tell us the type of a variable by using the `type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spearheads['con'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-exercise! Check the type of the following variables. Before running the `type()` function, try and predict what type each variable is. Did your expectation match the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "site = 'Ur'\n",
    "weight = 123.5\n",
    "number_of_sites = 5\n",
    "types = ['flint','bone']\n",
    "indy = {'name': 'Indiana Jones'}\n",
    "gold_found = True\n",
    "\n",
    "# check the type of these variables below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series object displays differently than a DataFrame object. To select a column as a DataFrame and not as a Series object, we will use two square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[['con']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using two square brackets, we can also select multiple columns at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[['num', 'mat', 'con']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've defined a subset of data, you can get the descriptive statistics for just those columns, again using `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[['weight', 'maxle', 'maxwi']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to calculate specific statistics for just one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[\"maxle\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for a couple of columns (note the double square brackets!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[[\"maxle\", \"maxwi\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - we've not used `print()` in the last couple of cells, as Jupyter Notebook automatically prints the output of Pandas functions and variables. However, it will only do this *1 time per cell*. Specifically, it will print the last line of code. So in the following cell, you'll only see the max, not the min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads[\"weight\"].min()\n",
    "spearheads[\"weight\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print multiple things in one cell, you will still need to use `print()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spearheads[\"weight\"].min())\n",
    "print(spearheads[\"weight\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here's a table with all the statistics that are available by default in Pandas.\n",
    "\n",
    "|  Function |            Description           |\n",
    "|:---------:|:--------------------------------:|\n",
    "|  count()  | Number of non-null observations  |\n",
    "|   sum()   | Sum of values                    |\n",
    "|   mean()  | Mean of Values                   |\n",
    "|  median() | Median of Values                 |\n",
    "|   mode()  | Mode of values                   |\n",
    "|   std()   | Standard Deviation of the Values |\n",
    "|   min()   | Minimum Value                    |\n",
    "|   max()   | Maximum Value                    |\n",
    "|   abs()   | Absolute Value                   |\n",
    "|   prod()  | Product of Values                |\n",
    "|  cumsum() | Cumulative Sum                   |\n",
    "| cumprod() | Cumulative Product               |\n",
    "\n",
    "### Filtering by column value\n",
    "\n",
    "Besides selecting certain columns, we can also select certain rows, based on a value in that row. Filtering data by certain values is similar to selecting columns.\n",
    "\n",
    "We type the name of the DataFrame followed by square brackets and then, instead of inserting a column name, we insert a True/False condition (like those in `if` statements!). For example, to select only rows containing bronze spearheads, we need to filter on value \"1\" in the \"mat\" column. So the True/False condition would be `spearheads['mat'] == 1`. The total code looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_spearheads = spearheads[ spearheads['mat'] == 1 ]\n",
    "bronze_spearheads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the subset of bronze spearheads, we can calculate statistics on just those rows, just like we did with columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_spearheads['weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare iron vs. bronze, see which is heavier on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iron_spearheads = spearheads[ spearheads['mat'] == 2 ]\n",
    "iron_spearheads['weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like iron spearheads are heavier on average!\n",
    "\n",
    "### Grouping by columns\n",
    "\n",
    "Do you remember pivot tables from Excel? Pandas can do those too! But in Pandas-speak, it's called grouping. The Pandas function `.groupby()` allows us to group data and perform calculations on the groups.\n",
    "\n",
    "For example, we might want to see the differences between iron and bronze spearheads. Instead of making 2 subsets (1 of iron, 1 of bronze), we can use grouping to make a table to summarise the differences.\n",
    "\n",
    "The first step to using groupby is to type the name of the DataFrame followed by `.groupby()` with the column we'd like to group on, such as \"mat\". Once it is grouped, you can use the same functions we used on whole columns/rows like in the previous cells, so using the square brackets with column name(s) and then apply the function. Below, we group the data by \"mat\" then count how many rows are in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.groupby(\"mat\")[\"mat\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so there's 20 bronze spearheads, and 18 iron ones. Let's double check the weight per material again, but this time using grouping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.groupby(\"mat\")[\"weight\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot shorter than manually selecting the columns and calculating the average separately! \n",
    "\n",
    "We can also get a statistic for every column, grouped by material. In that case we don't select a column with square brackets, but go straight to the `mean()` function after the `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.groupby(\"mat\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like Excel pivot tables, we can also select 2 columns we'd like to group by. This allows us to compare a statistic (in this case the mean) across 2 variables at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.groupby([\"mat\", \"cond\"])[\"weight\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that for bronze (mat 1), the better the condition (cond), the higher the weight, but this doesn't hold for iron... \n",
    "\n",
    "### Editing DataFrames\n",
    "\n",
    "So far, we've only created subsets of data and calculated statistics, but the data has stayed the same. Of course, just like in Excel, we can also edit DataFrames. As the column headers aren't very informative (and a bit confusing!), let's update them to be more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.rename(columns={\n",
    "    'num': 'number', \n",
    "    'mat': 'material', \n",
    "    'con': 'context', \n",
    "    'loo': 'has_loop', \n",
    "    'peg': 'has_peghole', \n",
    "    'cond': 'condition', \n",
    "    'maxle': 'max_length', \n",
    "    'socle': 'socket_length', \n",
    "    'maxwi': 'max_width', \n",
    "    'upsoc': 'upper_socket_width', \n",
    "    'losoc': 'lower_socket_width', \n",
    "    'mawit': 'maxwidth_lowersocket_distance'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of listing all the columns in one line of code, they are broken up, 1 per line, which aids readability. Also note the `inplace=True` option, this means that the changes should be done in the existing DataFrame, instead of returning a copy. If we now inspect the DataFrame, we'll see the updated column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.head() # by default, .head() shows the top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't need all the columns for our analysis, we can delete some with the `drop()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.drop(columns='maxwidth_lowersocket_distance', inplace=True)\n",
    "spearheads.tail() # by default, .tail() shows the last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarily, we can remove rows by putting the row's index in the `drop()` function. Let's imagine the last row is incorrect, and we want to delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the last row (index of that row is 37)\n",
    "spearheads.drop(37, inplace=True)\n",
    "\n",
    "# show updated tail\n",
    "spearheads.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another unclear aspect of this data is the use of codes for categories, e.g. using '1' for bronze and '2' for iron. Let's update that using the `replace()` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update category numbers to strings\n",
    "spearheads['material'] = spearheads['material'].replace(1, 'Bronze')\n",
    "spearheads['material'] = spearheads['material'].replace(2, 'Iron')\n",
    "\n",
    "# show random sample to check if it worked\n",
    "spearheads.sample(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did above is take the material column `spearheads['material']`, replace the number by a string `.replace(1, 'Bronze')`, and then save it back in the column by using `spearheads['material'] =`. \n",
    "\n",
    "Similarily, we can also combine information from multiple columns and save it in a new column. To create a new column, just type the DataFrame name and put the new column name in square brackets after it, just like you would do when creating a new key/value in a dictionary! For example, if we want to add the length/width ratio (or how elongated it is) of each spearhead, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads['length_width_ratio'] = spearheads['max_length'] / spearheads['max_width']\n",
    "spearheads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the length/width ratios, let's sort the dataframe on that column, so the most elongated spearheads are at the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort spearheads by l/w ratio\n",
    "spearheads.sort_values(by='length_width_ratio', inplace=True, ascending=False) # use ascending=False to reverse the order\n",
    "\n",
    "# show updated df\n",
    "spearheads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell the order of the rows has changed by looking at the index, it's now not starting at 0 and in order anymore!\n",
    "\n",
    "Another example of updating a column: if we want to update the `has_loop` column from using 1 = no, 2 = yes to using 0 = no, 1 = yes (the default way of storing Boolean true or false data), we can simply substract 1 from every number in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads['has_loop'] = spearheads['has_loop'] - 1\n",
    "spearheads.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-exercise!\n",
    "\n",
    "In the cell below, do the following:\n",
    "\n",
    "- Update `has_peghole` to use 1s and 0s, like we did with `has_loop`, so the data stays consistent\n",
    "- Use `head()`, `tail()` or `sample()` to check the data you've updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to CSV\n",
    "\n",
    "We've updated our data, but currently it's only stored in Python's memory. If you were to close this browser tab, the data ceases to exist (although you could very easily recreate it by running this code again, that's the beauty of code!). To save the data permanently, we'll output it to a new CSV file. We can use the `.to_csv()` method with a name for the file in quotation marks.\n",
    "\n",
    "In addition to a filename, we're also specifying that the Index (the bolded left-most column) is not included in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.to_csv(\"updated_spearheads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the modules folder where this script is stored, the CSV file should be there. Open it in Excel (or LibreOffice Calc) and look through the data, is everything as you expected it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next module preview: graphs!\n",
    "\n",
    "In the next module, we'll learn about graphs and plots, here's a sneak preview, showing how easy it is to make these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearheads.plot(kind='scatter', x=\"max_length\", y=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise\n",
    "\n",
    "Time to practice all you've learned in this module! In the cell(s) below, do the following steps. Note you can use as many cells as you want, this can be handy when displaying DataFrames (remember it only displays the last line of code?). Jupyter Notebook automatically adds another cell when you run the last one in the notebook.\n",
    "\n",
    "- Load the artefacts.csv file from the 'data' folder into a DataFrame and save it as a variable \n",
    "- Calculate and display the average number of artefacts found (mean of ART column)\n",
    "- Calculate and display the sum of all artefacts found (sum of ART column)\n",
    "- Make a subset of the DataFrame containing only the columns ART and MAT. Save it in a new variable and display it\n",
    "- Display the subset of rows where the material type (MAT) is ceramic (code '5')\n",
    "- Get the mean of ART, grouped by MAT\n",
    "- Change the column headings 'MAT' to 'material' and 'ART' to 'number_of_artefacts'\n",
    "- Change the material category numbers '1' and '5' to 'flint' and 'ceramic' respectively\n",
    "- Remove all rows where 'material' is 99 (which stands for 'unknown')\n",
    "- Sort the DataFrame by YCOORD\n",
    "- Write the updated DataFrame to a CSV file with a name of your choosing\n",
    "- Open the CSV file in Excel to check\n",
    "- BONUS: make a scatterplot of XCOORD and YCOORD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "spearheads-ml-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
